{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "import string\n",
    "\n",
    "import os \n",
    "from datetime import datetime\n",
    "import random\n",
    "import math\n",
    "from sklearn.cross_validation import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load in our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Going to use these 5 base models for the stacking\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import KFold;\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    # reassign id\n",
    "#     df.index = df.PassengerId\n",
    "\n",
    "    # drop not imp data\n",
    "#     df.drop(\"PassengerId\", axis=1, inplace=True)\n",
    "    \n",
    "    # avg_age\n",
    "#     avg_age = df['Age'].mean()\n",
    "    avg_age = df['Age'].median()\n",
    "#     std = df['Age'].std()\n",
    "#     mean = df['Age'].mean()\n",
    "#     size = len(df[pd.isnull(df['Age'])])\n",
    "#     age_null_random_list = np.random.randint(mean - std, mean + std, size=size)\n",
    "#     df.loc[pd.isnull(df['Age']), 'Age'] = age_null_random_list\n",
    "    \n",
    "    # age\n",
    "#     age_range = list(set(pd.qcut(df[pd.notnull(df['Age'])]['Age'], 5)))\n",
    "#     def agecat(age):\n",
    "#         if age in age_range[0]:\n",
    "#             cat = 0\n",
    "#         elif age in age_range[1]:\n",
    "#             cat = 1\n",
    "#         elif age in age_range[2]:\n",
    "#             cat = 2\n",
    "#         elif age in age_range[3]:\n",
    "#             cat = 3\n",
    "#         else:\n",
    "#             cat = 4\n",
    "#         return cat\n",
    "    \n",
    "    def agecat(age):\n",
    "        if age <= 16:\n",
    "            cat = 0\n",
    "        elif age > 16 and age <= 32:\n",
    "            cat = 1\n",
    "        elif age > 32 and age <= 48:\n",
    "            cat = 2\n",
    "        elif age < 48 and age <= 64:\n",
    "            cat = 3\n",
    "        else:\n",
    "            cat = 4\n",
    "        return cat\n",
    "    \n",
    "    \n",
    "    # fare\n",
    "#     fare_range = list(set(pd.qcut(df[pd.notnull(df['Fare'])]['Fare'], 7)))\n",
    "#     def farecat(f):\n",
    "#         if f in fare_range[0]:\n",
    "#             cat = 0\n",
    "#         elif f in fare_range[1]:\n",
    "#             cat = 1\n",
    "#         elif f in fare_range[2]:\n",
    "#             cat = 2\n",
    "#         elif f in fare_range[3]:\n",
    "#             cat = 3\n",
    "#         elif f in fare_range[4]:\n",
    "#             cat = 4\n",
    "#         elif f in fare_range[5]:\n",
    "#             cat = 5\n",
    "#         else:\n",
    "#             cat = 6\n",
    "#         return cat\n",
    "    \n",
    "    \n",
    "    def farecat(f):\n",
    "        if f <= 16:\n",
    "            cat = 0\n",
    "        elif f > 17 and f <= 32:\n",
    "            cat = 1\n",
    "        elif f > 32 and f <= 48:\n",
    "            cat = 2\n",
    "        elif f < 48 and f <= 64:\n",
    "            cat = 3\n",
    "        elif f < 64 and f <= 80:\n",
    "            cat = 4\n",
    "        elif f < 80 and f <= 96:\n",
    "            cat = 5\n",
    "        else:\n",
    "            cat = 6\n",
    "        return cat\n",
    "\n",
    "    \n",
    "    # avg_fare\n",
    "    fares_notnull = df[pd.notnull(df['Fare'])]['Fare']\n",
    "    avg_fare = fares_notnull.median()\n",
    "\n",
    "    # ticket\n",
    "    ticket_cat = {}\n",
    "    for ticket in df['Ticket']:\n",
    "        if ticket.isdigit():\n",
    "            ticket_cat[ticket] = 1\n",
    "        elif ticket.startswith('A'):\n",
    "            ticket_cat[ticket] = 2\n",
    "        elif ticket.startswith('C'):\n",
    "            ticket_cat[ticket] = 3\n",
    "        elif ticket.startswith('F'):\n",
    "            ticket_cat[ticket] = 4\n",
    "        elif ticket.startswith('P'):\n",
    "            ticket_cat[ticket] = 5\n",
    "        elif ticket.startswith('SOTON'):\n",
    "            ticket_cat[ticket] = 6\n",
    "        elif ticket.startswith('STON'):\n",
    "            ticket_cat[ticket] = 7\n",
    "        elif ticket.startswith('S'):\n",
    "            ticket_cat[ticket] = 8\n",
    "        elif ticket.startswith('W'):\n",
    "            ticket_cat[ticket] = 9\n",
    "        else:\n",
    "            ticket_cat[ticket] = 0\n",
    "            \n",
    "    ticket_cat1 = {}\n",
    "    for num, name in enumerate(list(set([item.split()[0].replace(\".\", \"\").replace(\"/\", \"\") for item in df['Ticket'] if not item.isdigit()]))):\n",
    "        ticket_cat1[name] = num\n",
    "    \n",
    "    # cabin\n",
    "    cabin_cat = {}\n",
    "    for cabin in df['Cabin']:\n",
    "        if pd.isnull(cabin):\n",
    "            cabin_cat[cabin] = 0\n",
    "        elif cabin.startswith('A'):\n",
    "            cabin_cat[cabin] = 1\n",
    "        elif cabin.startswith('B'):\n",
    "            cabin_cat[cabin] = 2\n",
    "        elif cabin.startswith('C'):\n",
    "            cabin_cat[cabin] = 3\n",
    "        elif cabin.startswith('D'):\n",
    "            cabin_cat[cabin] = 4\n",
    "        elif cabin.startswith('E'):\n",
    "            cabin_cat[cabin] = 5\n",
    "        else:\n",
    "            cabin_cat[cabin] = 0\n",
    "    \n",
    "    # embarked\n",
    "    embarked_cat = {}\n",
    "    for embarked in df['Embarked']:\n",
    "        if pd.isnull(embarked):\n",
    "            embarked_cat[embarked] = 0\n",
    "        elif embarked.startswith('S'):\n",
    "            embarked_cat[embarked] = 0\n",
    "        elif embarked.startswith('Q'):\n",
    "            embarked_cat[embarked] = 1\n",
    "        elif embarked.startswith('C'):\n",
    "            embarked_cat[embarked] = 2\n",
    "            \n",
    "            \n",
    "    # title\n",
    "    title_mapping= {\n",
    "        'Ms':\"Miss\",\n",
    "        'Mlle':\"Miss\",\n",
    "        'Miss':\"Miss\",\n",
    "        'Mrs':\"Mrs\",\n",
    "        'Mme':\"Mrs\",\n",
    "        'MrsMartin(ElizabethL':\"Mrs\",\n",
    "        'Mr':\"Mr\"\n",
    "        }\n",
    "    \n",
    "    title_cat = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    \n",
    "    # Name_with specail chars\n",
    "    def withspecailchar(name):\n",
    "        for char in name:\n",
    "            if char in string.punctuation:\n",
    "                return 1\n",
    "        return 0\n",
    "    \n",
    "    def applyfun(row):\n",
    "        row['Has_Cabin'] = 0 if pd.isnull(row['Cabin']) else 1\n",
    "        row['Cabin'] = cabin_cat.get(row['Cabin'])\n",
    "\n",
    "        row['Age'] = row['Age'] if pd.notnull(row['Age']) else avg_age\n",
    "        row['Age_Cat'] = agecat(row['Age'])\n",
    "        row['Age_Lower_than_15'] = 1 if row['Age'] < 15 else 0\n",
    "        row['Age_Higher_than_75'] = 1 if row['Age'] > 75 else 0\n",
    "\n",
    "        row['Fare'] = row['Fare'] if pd.notnull(row['Fare']) else avg_fare\n",
    "        row['Fare_log10'] = math.log(row['Fare'], 10) if  row['Fare'] != 0 else 0\n",
    "        row['Fare_log2'] = math.log(row['Fare'], 2) if  row['Fare'] != 0 else 0\n",
    "\n",
    "        row['Fare_Cat'] = farecat(row['Fare'])\n",
    "        row['High_Price_Fare'] = 1 if row['Fare'] > 200 else 0\n",
    "\n",
    "        row['Ticket'] = ticket_cat.get(row['Ticket'])\n",
    "        processed_ticket = row['Ticket'].split()[0].replace(\".\", \"\").replace(\"/\", \"\") if not str(row['Ticket']).isdigit() else None\n",
    "#         row['Ticket1'] = ticket_cat1.get(processed_ticket) if processed_ticket != None else 30\n",
    "\n",
    "        row['Embarked'] = embarked_cat.get(row['Embarked'])\n",
    "        row['Sex'] = 1 if row['Sex'] == 'male' else 0\n",
    "\n",
    "        row['Name_Length'] = len(row['Name'])\n",
    "        row['Name_With_Special_Char'] = withspecailchar(row['Name'].replace(',', \"\").replace('.', \"\"))\n",
    "        row['Family_Size'] = row['SibSp'] + row['Parch']\n",
    "        row['Is_Alone']= 1 if row['Family_Size'] == 1 else 0\n",
    "        \n",
    "        call = re.search(r'\\,.+\\.', row['Name']).group(0).replace(\",\", \"\").replace(\".\", \"\").replace(\" \", \"\")\n",
    "        call_cat = title_cat.get(title_mapping.get(call, \"Rare\"))\n",
    "        row['Title'] = call_cat\n",
    "#         row['Mother'] = 1 if row['Age'] >18 and row['Parch'] > 0 and call != 'Miss' else 0\n",
    "        return row\n",
    "    \n",
    "    df = df.apply(applyfun, axis=1)\n",
    "    df.drop('Name', axis=1, inplace=True)\n",
    "    df.drop('Fare', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891,)\n",
      "(891, 21)\n",
      "(418, 21)\n"
     ]
    }
   ],
   "source": [
    "# Input Data Preparation\n",
    "df = pd.read_csv('train.csv')\n",
    "df = preprocess(df)\n",
    "x_train = np.matrix(df.drop(['Survived','PassengerId'], axis=1))\n",
    "y_train = np.array(df['Survived'])\n",
    "\n",
    "df_test = pd.read_csv('test.csv')\n",
    "ID = df_test['PassengerId']\n",
    "x_test = np.matrix(preprocess(df_test.drop('PassengerId', axis=1)))\n",
    "\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful parameters which will come in handy later on\n",
    "ntrain = df.shape[0]\n",
    "ntest = df_test.shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "kf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n",
    "\n",
    "# Class to extend the Sklearn classifier\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        if seed == 0:\n",
    "            params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)\n",
    "    \n",
    "# Class to extend XGboost classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof_tuning(clf, x_train, y_train, x_test):\n",
    "    x_train_split, x_valid_split, y_train_split, y_valid_split = train_test_split(x_train, y_train, test_size=0.4, random_state=4242)\n",
    "    clf.train(x_train_split, y_train_split)\n",
    "    x_valid_predict = clf.predict(x_valid_split)  \n",
    "    accuracy1 = np.sum(x_valid_predict == y_valid_split)/len(x_valid_predict)\n",
    "    \n",
    "    x_train_split, x_valid_split, y_train_split, y_valid_split = train_test_split(x_train, y_train, test_size=0.4, random_state=1111)\n",
    "    clf.train(x_train_split, y_train_split)\n",
    "    x_valid_predict = clf.predict(x_valid_split)  \n",
    "    accuracy2 = np.sum(x_valid_predict == y_valid_split)/len(x_valid_predict)\n",
    "\n",
    "    return (accuracy1 + accuracy2) / 2\n",
    "\n",
    "\n",
    "# param tuning\n",
    "def gen_params(input_params):\n",
    "    test_params = []\n",
    "    for i in range(1000):\n",
    "        param = {}\n",
    "        for key, values in input_params.items():\n",
    "            param[key] = np.random.choice(values)\n",
    "        test_params.append(param)\n",
    "\n",
    "    df_test_params = pd.DataFrame(test_params)\n",
    "    df_test_params = df_test_params.drop_duplicates()\n",
    "    test_params = df_test_params.T.to_dict()\n",
    "    return [value for key, value in test_params.items()]\n",
    "\n",
    "\n",
    "def find_best_params(test_params, clf_type):\n",
    "    best_score = 0\n",
    "    best_param = {}\n",
    "    for num, param in enumerate(test_params):\n",
    "        clf = SklearnHelper(clf=clf_type, seed=SEED, params=param)\n",
    "        accuracy = get_oof_tuning(clf, x_train, y_train, x_test) # Random Forest\n",
    "        if accuracy > best_score:\n",
    "            best_score = accuracy\n",
    "            best_param = param\n",
    "            print(\"number:\", num)\n",
    "            print(\"params:\", best_param)\n",
    "            print(\"accuracy:\", best_score)\n",
    "    return best_score, best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_bestscore = [{'params': {'criterion': 'gini',\n",
    "#    'max_depth': 28,\n",
    "#    'max_features': 'sqrt',\n",
    "#    'min_samples_leaf': 2,\n",
    "#    'n_estimators': 335,\n",
    "#    'n_jobs': -1,\n",
    "#    'random_state': 0,\n",
    "#    'verbose': 0,\n",
    "#    'warm_start': True},\n",
    "#   'score': 0.9079685746352413},\n",
    "#  {'params': {'criterion': 'gini',\n",
    "#    'max_depth': 28,\n",
    "#    'max_features': None,\n",
    "#    'min_samples_leaf': 2,\n",
    "#    'n_estimators': 337,\n",
    "#    'n_jobs': -1,\n",
    "#    'random_state': 0,\n",
    "#    'verbose': 0,\n",
    "#    'warm_start': True},\n",
    "#   'score': 0.92368125701459036},\n",
    "#  {'params': {'criterion': 'gini',\n",
    "#    'max_depth': 25,\n",
    "#    'max_features': None,\n",
    "#    'min_samples_leaf': 2,\n",
    "#    'n_estimators': 345,\n",
    "#    'n_jobs': -1,\n",
    "#    'random_state': 0,\n",
    "#    'verbose': 0,\n",
    "#    'warm_start': True},\n",
    "#   'score': 0.92480359147025815}]\n",
    "\n",
    "\n",
    "\n",
    "# et_bestscore = [{'params': {'max_depth': 20,\n",
    "#    'max_features': 'log2',\n",
    "#    'min_samples_leaf': 2,\n",
    "#    'n_estimators': 160,\n",
    "#    'n_jobs': -1,\n",
    "#    'random_state': 0,\n",
    "#    'verbose': 0},\n",
    "#   'score': 0.82940516273849607},\n",
    "#  {'params': {'max_depth': 20,\n",
    "#    'max_features': 'log2',\n",
    "#    'min_samples_leaf': 2,\n",
    "#    'n_estimators': 162,\n",
    "#    'n_jobs': -1,\n",
    "#    'random_state': 0,\n",
    "#    'verbose': 0},\n",
    "#   'score': 0.83052749719416386}]\n",
    "\n",
    "\n",
    "\n",
    "# ada_bestscore = [{'params': {'algorithm': 'SAMME.R', \n",
    "#     'learning_rate': 0.75, \n",
    "#     'n_estimators': 1000, \n",
    "#     'random_state': 0},\n",
    "#   'score': 0.81481481481481477},\n",
    "#  {'params': {'algorithm': 'SAMME',\n",
    "#    'learning_rate': 0.75,\n",
    "#    'n_estimators': 900,\n",
    "#    'random_state': 0},\n",
    "#   'score': 0.8204264870931538}]\n",
    "\n",
    "\n",
    "\n",
    "# gb_bestscore = [{'params': {'max_depth': 10,\n",
    "#    'max_features': 'sqrt',\n",
    "#    'min_samples_leaf': 2,\n",
    "#    'n_estimators': 1500,\n",
    "#    'random_state': 0,\n",
    "#    'verbose': 0},\n",
    "#   'score': 0.81593714927048255}]\n",
    "\n",
    "\n",
    "# svc_bestscore = [{'params': {'C': 1, \n",
    "#     'kernel': 'linear', \n",
    "#     'random_state': 0},\n",
    "#   'score': 0.811447811448}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_bestscore = [{'params': {'criterion': 'gini',\n",
    "#    'max_depth': 5,\n",
    "#    'max_features': 'sqrt',\n",
    "#    'min_samples_leaf': 2,\n",
    "#    'n_estimators': 200,\n",
    "#    'n_jobs': -1,\n",
    "#    'random_state': 0,\n",
    "#    'verbose': 0,\n",
    "#    'warm_start': True},\n",
    "#   'score': 0.834733893557423},\n",
    "#  {'params': {'criterion': 'gini',\n",
    "#    'max_depth': 5,\n",
    "#    'max_features': 'sqrt',\n",
    "#    'min_samples_leaf': 2,\n",
    "#    'n_estimators': 190,\n",
    "#    'n_jobs': -1,\n",
    "#    'random_state': 0,\n",
    "#    'verbose': 0,\n",
    "#    'warm_start': True},\n",
    "#   'score': 0.84033613445378152}]\n",
    "\n",
    "# et_bestscore = [{'params': {'max_depth': 10,\n",
    "#    'max_features': 'sqrt',\n",
    "#    'min_samples_leaf': 2,\n",
    "#    'n_estimators': 200,\n",
    "#    'n_jobs': -1,\n",
    "#    'random_state': 0,\n",
    "#    'verbose': 0},\n",
    "#   'score': 0.82072829131652658}]\n",
    "\n",
    "# ada_bestscore = [{'params': {'algorithm': 'SAMME',\n",
    "#    'learning_rate': 0.75,\n",
    "#    'n_estimators': 900,\n",
    "#    'random_state': 0},\n",
    "#   'score': 0.8123249299719888},\n",
    "#  {'params': {'algorithm': 'SAMME',\n",
    "#    'learning_rate': 0.5,\n",
    "#    'n_estimators': 100,\n",
    "#    'random_state': 0},\n",
    "#   'score': 0.81512605042016806},\n",
    "#  {'params': {'algorithm': 'SAMME',\n",
    "#    'learning_rate': 0.5,\n",
    "#    'n_estimators': 130,\n",
    "#    'random_state': 0},\n",
    "#   'score': 0.81792717086834732},\n",
    "#  {'params': {'algorithm': 'SAMME',\n",
    "#    'learning_rate': 0.45,\n",
    "#    'n_estimators': 120,\n",
    "#    'random_state': 0},\n",
    "#   'score': 0.82072829131652658}]\n",
    "\n",
    "# gb_bestscore = [{'params': {'max_depth': 20,\n",
    "#    'max_features': 'sqrt',\n",
    "#    'min_samples_leaf': 2,\n",
    "#    'n_estimators': 1600,\n",
    "#    'random_state': 0,\n",
    "#    'verbose': 0},\n",
    "#   'score': 0.80952380952380953},\n",
    "#  {'params': {'max_depth': 50,\n",
    "#    'max_features': 'sqrt',\n",
    "#    'min_samples_leaf': 2,\n",
    "#    'n_estimators': 2500,\n",
    "#    'random_state': 0,\n",
    "#    'verbose': 0},\n",
    "#   'score': 0.81792717086834732}]\n",
    "\n",
    "# svc_bestscore = [{'params': {'C': 1, 'kernel': 'linear', 'random_state': 0},\n",
    "#   'score': 0.82352941176470584}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_bestscore = [{'params': {'criterion': 'gini',\n",
    "   'max_depth': 5,\n",
    "   'max_features': 'sqrt',\n",
    "   'min_samples_leaf': 2,\n",
    "   'n_estimators': 190,\n",
    "   'n_jobs': -1,\n",
    "   'random_state': 0,\n",
    "   'verbose': 0,\n",
    "   'warm_start': True},\n",
    "  'score': 0.85854341736694684},\n",
    " {'params': {'criterion': 'gini',\n",
    "   'max_depth': 10,\n",
    "   'max_features': None,\n",
    "   'min_samples_leaf': 2,\n",
    "   'n_estimators': 100,\n",
    "   'n_jobs': -1,\n",
    "   'random_state': 0,\n",
    "   'verbose': 0,\n",
    "   'warm_start': True},\n",
    "  'score': 0.87394957983193278},\n",
    " {'params': {'criterion': 'gini',\n",
    "   'max_depth': 20,\n",
    "   'max_features': None,\n",
    "   'min_samples_leaf': 2,\n",
    "   'n_estimators': 200,\n",
    "   'n_jobs': -1,\n",
    "   'random_state': 0,\n",
    "   'verbose': 0,\n",
    "   'warm_start': True},\n",
    "  'score': 0.87675070028011204}]\n",
    "\n",
    "et_bestscore = []\n",
    "\n",
    "ada_bestscore = []\n",
    "\n",
    "gb_bestscore = []\n",
    "\n",
    "svc_bestscore = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number: 0\n",
      "params: {'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 220, 'n_jobs': -1, 'verbose': 0, 'warm_start': True, 'random_state': 0}\n",
      "accuracy: 0.865546218487\n",
      "number: 2\n",
      "params: {'criterion': 'gini', 'max_depth': 23, 'max_features': None, 'min_samples_leaf': 2, 'n_estimators': 200, 'n_jobs': -1, 'verbose': 0, 'warm_start': True, 'random_state': 0}\n",
      "accuracy: 0.878151260504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'params': {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'max_features': 'sqrt',\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 190,\n",
       "   'n_jobs': -1,\n",
       "   'random_state': 0,\n",
       "   'verbose': 0,\n",
       "   'warm_start': True},\n",
       "  'score': 0.8585434173669468},\n",
       " {'params': {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'max_features': None,\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 100,\n",
       "   'n_jobs': -1,\n",
       "   'random_state': 0,\n",
       "   'verbose': 0,\n",
       "   'warm_start': True},\n",
       "  'score': 0.8739495798319328},\n",
       " {'params': {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'max_features': None,\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 200,\n",
       "   'n_jobs': -1,\n",
       "   'random_state': 0,\n",
       "   'verbose': 0,\n",
       "   'warm_start': True},\n",
       "  'score': 0.876750700280112},\n",
       " {'params': {'criterion': 'gini',\n",
       "   'max_depth': 23,\n",
       "   'max_features': None,\n",
       "   'min_samples_leaf': 2,\n",
       "   'n_estimators': 200,\n",
       "   'n_jobs': -1,\n",
       "   'random_state': 0,\n",
       "   'verbose': 0,\n",
       "   'warm_start': True},\n",
       "  'score': 0.87815126050420167}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': [180, 200, 220], # how many trees?\n",
    "    'max_depth': [19, 20, 21, 23],\n",
    "    'n_jobs': [-1],\n",
    "    'min_samples_leaf': [2],       # minimum samples in a leaf\n",
    "    'max_features' : ['sqrt', 'log2', None],\n",
    "    'criterion':['gini'],\n",
    "    'verbose': [0],                     # don't tell me what happened\n",
    "     'warm_start': [True]               # progress when generating new trees\n",
    "}\n",
    "\n",
    "test_params = gen_params(rf_params)\n",
    "best_score, best_param = find_best_params(test_params, RandomForestClassifier)\n",
    "\n",
    "if rf_bestscore == [] or (best_score > sorted(rf_bestscore, key=lambda x:x['score'], reverse=True)[0]['score']):\n",
    "    rf_bestscore.append({'params':best_param, 'score':best_score})\n",
    "\n",
    "rf_bestscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_params = {\n",
    "    'n_jobs': [-1],\n",
    "    'n_estimators':[191, 193, 195, 197, 199],\n",
    "    'max_features': ['log2', 'sqrt', None],\n",
    "    'max_depth': [10],\n",
    "    'min_samples_leaf': [2],\n",
    "    'verbose': [0]\n",
    "}\n",
    "\n",
    "test_params = gen_params(et_params)\n",
    "best_score, best_param = find_best_params(test_params, ExtraTreesClassifier)\n",
    "\n",
    "if et_bestscore == [] or (best_score > sorted(et_bestscore, key=lambda x:x['score'], reverse=True)[0]['score']):\n",
    "    et_bestscore.append({'params':best_param, 'score':best_score})\n",
    "\n",
    "et_bestscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_params = {\n",
    "    'n_estimators': [115, 120, 125],\n",
    "    'learning_rate' : [0.41, 0.43, 0.45, 0.47, 0.49],\n",
    "    'algorithm' : ['SAMME']\n",
    "}\n",
    "\n",
    "test_params = gen_params(ada_params)\n",
    "\n",
    "for item in test_params:\n",
    "    for key, value in item.items():\n",
    "        if key == 'n_estimators':\n",
    "            item[key] = int(value)\n",
    "\n",
    "best_score, best_param = find_best_params(test_params, AdaBoostClassifier)\n",
    "\n",
    "if ada_bestscore == [] or (best_score > sorted(ada_bestscore, key=lambda x:x['score'], reverse=True)[0]['score']):\n",
    "    ada_bestscore.append({'params':best_param, 'score':best_score})\n",
    "\n",
    "ada_bestscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_params = {\n",
    "    'n_estimators': [1600, 1800, 2500, 3000, 4000],\n",
    "    'max_features': ['log2', 'sqrt', None],\n",
    "    'max_depth': [30, 50, 60],\n",
    "    'min_samples_leaf': [2],\n",
    "    'verbose': [0]\n",
    "}\n",
    "\n",
    "test_params = gen_params(gb_params)\n",
    "best_score, best_param = find_best_params(test_params, GradientBoostingClassifier)\n",
    "\n",
    "if gb_bestscore == [] or (best_score > sorted(gb_bestscore, key=lambda x:x['score'], reverse=True)[0]['score']):\n",
    "    gb_bestscore.append({'params':best_param, 'score':best_score})\n",
    "\n",
    "gb_bestscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_params_Li = [\n",
    "    {\n",
    "    'C' : [1,2,3,5,10],\n",
    "    'kernel' : ['linear', 'rbf', 'sigmoid'],  ## poly takes too much time\n",
    "    },\n",
    "#     {\n",
    "#     'C' : [1,2,3],\n",
    "#     'kernel' : ['poly'],\n",
    "#     'degree': [2,3,4,5] # if use poly\n",
    "#     },\n",
    "#     {\n",
    "#     'C' : [1,2,3,5,10],\n",
    "#     'kernel' : ['rbf', 'sigmoid'],\n",
    "#     'gamma' : ['auto', 0.2, 0.3, 0.4]\n",
    "#     }\n",
    "]\n",
    "\n",
    "\n",
    "for svc_params in svc_params_Li:\n",
    "    print('==========================')\n",
    "    print('new svc_params')\n",
    "    test_params = gen_params(svc_params)\n",
    "\n",
    "    for item in test_params:\n",
    "        for key, value in item.items():\n",
    "            if key == 'kernel':\n",
    "                item[key] = str(value)\n",
    "            if key == 'C':\n",
    "                item[key] = int(value)\n",
    "            if key == 'degree':\n",
    "                item[key] = int(value)\n",
    "            if key == 'gamma':\n",
    "                if value != 'auto':\n",
    "                    item[key] = float(value)\n",
    "                \n",
    "    best_score, best_param = find_best_params(test_params, SVC)\n",
    "\n",
    "    if svc_bestscore == [] or (best_score > sorted(svc_bestscore, key=lambda x:x['score'], reverse=True)[0]['score']):\n",
    "        svc_bestscore.append({'params':best_param, 'score':best_score})\n",
    "\n",
    "    from pprint import pprint\n",
    "    pprint(svc_bestscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 三次tuning random forest的比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params1 = {'criterion': 'gini',\n",
    "   'max_depth': 25,\n",
    "   'max_features': None,\n",
    "   'min_samples_leaf': 2,\n",
    "   'n_estimators': 345,\n",
    "   'n_jobs': -1,\n",
    "   'verbose': 0,\n",
    "   'warm_start': True}\n",
    "# 0.75598\n",
    "\n",
    "rf_params2 = {'criterion': 'gini',\n",
    "   'max_depth': 5,\n",
    "   'max_features': 'sqrt',\n",
    "   'min_samples_leaf': 2,\n",
    "   'n_estimators': 190,\n",
    "   'n_jobs': -1,\n",
    "   'verbose': 0,\n",
    "   'warm_start': True}\n",
    "# 0.78468\n",
    "\n",
    "rf_params3 = {'criterion': 'gini',\n",
    "   'max_depth': 20,\n",
    "   'max_features': None,\n",
    "   'min_samples_leaf': 2,\n",
    "   'n_estimators': 200,\n",
    "   'n_jobs': -1,\n",
    "   'verbose': 0,\n",
    "   'warm_start': True}\n",
    "# 0.76555\n",
    "\n",
    "rf_params4 = {'criterion': 'gini',\n",
    "   'max_depth': 4,\n",
    "   'max_features': 'sqrt',\n",
    "   'min_samples_leaf': 2,\n",
    "   'n_estimators': 180,\n",
    "   'n_jobs': -1,\n",
    "   'verbose': 0,\n",
    "   'warm_start': True}\n",
    "\n",
    "\n",
    "# rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params1)\n",
    "# rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params2)\n",
    "# rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params3)\n",
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params4)\n",
    "\n",
    "rf_oof_train, rf_oof_test, rf_accuracy = get_oof(rf,x_train, y_train, x_test) # Random Forest\n",
    "# Generate Submission File \n",
    "predictions = rf_oof_test.reshape(len(rf_oof_test), ).astype(int)\n",
    "\n",
    "StackingSubmission = pd.DataFrame({ 'PassengerId': ID, 'Survived': predictions })\n",
    "\n",
    "nowtime = str(datetime.now())\n",
    "for char in string.punctuation:\n",
    "    nowtime = nowtime.replace(char, \"\").replace(\" \", \"\")\n",
    "\n",
    "# filename = os.path.join(\"submission\", nowtime[:14]+\"rf_params1.csv\")\n",
    "# filename = os.path.join(\"submission\", nowtime[:14]+\"rf_params2.csv\")\n",
    "# filename = os.path.join(\"submission\", nowtime[:14]+\"rf_params3.csv\")\n",
    "filename = os.path.join(\"submission\", nowtime[:14]+\"rf_params4.csv\")\n",
    "\n",
    "StackingSubmission.to_csv(filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
